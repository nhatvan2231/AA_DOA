{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e559a1d-8446-4ca7-84d8-efc7db330869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 19:54:43.705618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744055683.718899 3770876 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744055683.723236 3770876 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-07 19:54:43.737620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5139c6c6-6cfd-4435-a035-092d534f17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniPINN(tf.keras.Model):\n",
    "    def __init__(self, n_channels, array_geometry, he_initializer = True, floormod=False):\n",
    "        super().__init__()\n",
    "        # Fixed metrics\n",
    "        self.mse_metric = tf.keras.metrics.MeanSquaredError(name='mse')\n",
    "        self.mae_metric = tf.keras.metrics.MeanAbsoluteError(name='mae')\n",
    "\n",
    "        # Use floormod\n",
    "        self.floormod = floormod\n",
    "       \n",
    "        # Target array geometry\n",
    "        self.array_geometry = array_geometry\n",
    "        \n",
    "        \n",
    "        self.initializer = tf.keras.initializers.HeNormal(1561)\n",
    "        if not he_initializer:\n",
    "            self.initializer = tf.keras.initializers.GlorotUniform(1561)\n",
    "        self.net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(n_channels),\n",
    "            tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=256, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=128, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=64, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=32, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=16, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=8, activation='relu', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=1, activation = 'linear')\n",
    "        ]) \n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "    def train_step(self, dataset):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, c, y = dataset\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            self.loss.set_param(x,c)\n",
    "            loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "               metric.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        \n",
    "    def test_step(self, dataset):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, c, y = dataset\n",
    "        y_pred = self(x, training=False)  # Forward pass\n",
    "        # Compute the loss value\n",
    "        # (the loss function is configured in `compile()`)\n",
    "        self.loss.set_param(x,c)\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # Compute gradients\n",
    "        \n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            #print(metric.name)\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict(self, inputs,verbose=False):\n",
    "        output = self.net(inputs)\n",
    "        if self.floormod:\n",
    "            #output = tf.math.floormod(output,360.0)\n",
    "            output = tf.clip_by_value(output,0.0,359.99)\n",
    "        return output\n",
    "    def call(self, inputs):\n",
    "        output = self.net(inputs)\n",
    "        if self.floormod:\n",
    "            output = tf.clip_by_value(output,0.0,359.99)\n",
    "            #output = tf.math.floormod(output,360.0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4cf220-a56d-47dc-ad45-f5ab0a4910a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniPINNLoss(tf.keras.losses.Loss):\n",
    "    # MniPINN Loss introducing physic to the model\n",
    "    # Taus = R * cos(Theta) / C\n",
    "    # Taus is time delays\n",
    "    # R reference for a fixed reference time delay\n",
    "    # R is the array geometry\n",
    "    # C is speed\n",
    "    def __init__(self, target_aa_geo, ref_aa_geo, norm, clambda=0.0):\n",
    "        super().__init__()\n",
    "        self.clambda = clambda\n",
    "        self.r0 = ref_aa_geo\n",
    "        self.r = target_aa_geo # (num of channels,2)\n",
    "        self.norm = norm\n",
    "        self.taus = None\n",
    "        self.c = None\n",
    "    def set_param(self, taus, c):\n",
    "        self.taus = taus\n",
    "        self.c = c\n",
    "    def cossin_loss(self, y_actual, y_predicted):\n",
    "        # convert degree to radian\n",
    "        actual_rad = y_actual*np.pi/180\n",
    "        predicted_rad = y_predicted*np.pi/180\n",
    "        \n",
    "        # the cosine and sine loss\n",
    "        cos_loss = 1 - tf.math.cos(actual_rad - predicted_rad)\n",
    "        sin_loss = tf.math.sin(actual_rad - predicted_rad)\n",
    "        \n",
    "        # loss \n",
    "        loss = cos_loss + sin_loss\n",
    "        return loss\n",
    "    def cos_loss(self, y_actual, y_predicted):\n",
    "        # convert degree to radian\n",
    "        actual_rad = y_actual*np.pi/180\n",
    "        predicted_rad = y_predicted*np.pi/180\n",
    "        \n",
    "        # the cosine loss\n",
    "        loss = 1 - tf.math.cos(actual_rad-predicted_rad)\n",
    "        return loss\n",
    "        \n",
    "    def call(self, y_actual, y_predicted):\n",
    "        # convert degree to radian\n",
    "        actual_rad = y_actual*np.pi/180\n",
    "        predicted_rad = y_predicted*np.pi/180\n",
    "\n",
    "        # slowness vector (2,None)\n",
    "        # since only dealing with azimuth\n",
    "        x_dir = tf.math.cos(predicted_rad) / self.c\n",
    "        y_dir = tf.math.sin(predicted_rad) / self.c\n",
    "        slowness = tf.stack([x_dir, y_dir],1) #/ self.c\n",
    "\n",
    "        # calculate the time delay for the reference channel\n",
    "        taus_ref = -tf.tensordot(slowness, self.r0, axes=[[1],[0]]) / self.norm\n",
    "        taus_ref = tf.reshape(taus_ref, [-1,1,1])\n",
    "\n",
    "        # calculate the time delays from predicted angle\n",
    "        taus_hat = -tf.tensordot(slowness, self.r, axes = [[1],[1]]) / self.norm\n",
    "        # shift the predicted time delays to the reference channel\n",
    "        taus_hat -= taus_ref\n",
    "        # match the predicted taus dimension\n",
    "        taus = tf.expand_dims(self.taus, 1)\n",
    "        \n",
    "        # calculate the physical loss\n",
    "        phys_loss = tf.keras.losses.MSE(taus, taus_hat)\n",
    "\n",
    "        # MSE loss\n",
    "        #simple_loss = tf.keras.losses.MSE(y_actual, y_predicted)\n",
    "        #simple_loss = tf.keras.losses.MSE(actual_rad, predicted_rad)\n",
    "        #cossin_loss = self.cossin_loss(y_actual, y_predicted)\n",
    "        cos_loss = self.cos_loss(y_actual, y_predicted)\n",
    "\n",
    "        # Total loss\n",
    "        loss = tf.reshape(cos_loss, [-1,1]) + self.clambda*phys_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5ee613-4ade-44d6-bc67-ae5970eb6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector_loss(y_actual, y_predicted):\n",
    "    # Select the minimum angle to deal with wrap around problem\n",
    "    loss = tf.math.minimum(360-tf.math.abs(y_predicted-y_actual), \\\n",
    "                           tf.math.abs(y_predicted-y_actual))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba9e580-03e7-4819-bdf9-1c05e6fcfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_evaluation(list_channels, AA_geometry, \\\n",
    "                        inputs, speeds, labels, norm, clambda = 0.0,\n",
    "                        he_initializer=True, floormod=True, \n",
    "                        epochs = 50, plot = False, save_fig = False,verbose=False):\n",
    "    # trained models\n",
    "    models = []\n",
    "    # models losses history\n",
    "    losses = []\n",
    "    # evluation scores\n",
    "    evaluates = []\n",
    "    # reference channel at channel 0 for time delays\n",
    "    ref_geometry = tf.constant(AA_geometry[0][:2], dtype=float)\n",
    "\n",
    "    # train models for each selected channels in the list of channels\n",
    "    for channels in list_channels:\n",
    "        # Get the geometry of the channels only in x and y planes\n",
    "        array_geometry = tf.constant(AA_geometry[channels][:,:2], dtype=float)\n",
    "        # pack selected channels data into tensorflow dataset\n",
    "        dataset = DataSetPacker(inputs, speeds, labels, channels)\n",
    "        \n",
    "        # split dataset into train, validation, and test dataset\n",
    "        train_dataset, val_dataset, test_dataset = dataset.split(shuffle=False)\n",
    "        # Initialize the model\n",
    "        model = MiniPINN(np.shape(channels), array_geometry, he_initializer, floormod)\n",
    "        # Compile model\n",
    "        model.compile(optimizer='adam', loss=MiniPINNLoss(array_geometry, ref_geometry, norm, clambda))#, metrics=['mse','mae'])\n",
    "        #model.compile(optimizer='adam', loss='mse', metrics=['mse','mae'])\n",
    "        l = model.fit(train_dataset.batch(32), epochs=epochs, validation_data = val_dataset.batch(32), verbose=verbose)\n",
    "        # Train model\n",
    "        #l = model.fit(train_dataset.batch(32), epochs=epochs, verbose=True)\n",
    "        # Get model score\n",
    "        eva = EvaluateModel(model, channels, test_dataset)\n",
    "        eva.evaluate(verbose=True)\n",
    "        #eva = EvaluateModel.evaluate(model, test_dataset, False)\n",
    "        if plot:\n",
    "            if save_fig:\n",
    "                eva.plot_training(l, save_dir = 'plot/history/')\n",
    "                eva.plot_evaluation(save_dir = 'plot/evaluation/')\n",
    "            else:\n",
    "                eva.plot_training(l)\n",
    "                eva.plot_evaluation()\n",
    "        models.append(model)\n",
    "        losses.append(l)\n",
    "        evaluates.append(eva)\n",
    "    return models, evaluates, l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db9172-574d-4391-8f46-4f9266034d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

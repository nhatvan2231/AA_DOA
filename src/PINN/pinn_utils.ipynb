{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70483dc-d48a-4930-aeb7-9dd0207c5312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 15:17:53.298141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745853473.308489  985717 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745853473.311651  985717 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-28 15:17:53.323162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb21ad-24d0-4dfd-8756-ac325a16777c",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329908d1-c096-4c0f-9465-80112d3f5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtract:\n",
    "    def __init__(self, path_dir, n_channels, n_samples, arr_geometry):\n",
    "        # private variable\n",
    "        # path to data\n",
    "        self._path_dir = path_dir\n",
    "        \n",
    "        # number of channels in the array\n",
    "        self._n_channels = n_channels\n",
    "        \n",
    "        # number of samples of the signal\n",
    "        self._n_signal_samples = n_samples\n",
    "\n",
    "        # number of data samples\n",
    "        self.n_data_samples = None\n",
    "\n",
    "        # array geometry\n",
    "        self.arr_geometry = arr_geometry\n",
    "        \n",
    "        # list of raw signal file names\n",
    "        self._files_raw = None\n",
    "        \n",
    "        # list of signal information file names\n",
    "        self._files_dat = None\n",
    "\n",
    "        # Sample Frequency\n",
    "        self.sampleFreq = None\n",
    "        \n",
    "        # Space and time of the wave\n",
    "        # Measured pressure at mirophone in space\n",
    "        # Theta / angle at measured pressure\n",
    "        # Shape: (num of data samples, num of channels, num of signal samples, 1 or 2)\n",
    "        self.space = None\n",
    "        self.time = None\n",
    "        self.pres = None\n",
    "        self.theta = None\n",
    "        self.space_time_pres_theta = None\n",
    "\n",
    "        # subset to return\n",
    "        self.sub_space_time_pres_theta = None\n",
    "        # TODO:speeds\n",
    "        #self._speeds = None\n",
    "        \n",
    "        # extract angels from dat files\n",
    "        self._extract_signal_info()\n",
    "        # extract taus from bin files\n",
    "        self._extract_raw_signal()\n",
    "        # geometry to space\n",
    "        self._geometry_to_space()\n",
    "        # pack data into 1\n",
    "        self._pack_data()\n",
    "        # set a upper and lower angles limit\n",
    "        self.set_bound()\n",
    "\n",
    "\n",
    "    # This function uses for sorting files\n",
    "    def _key(self, file):\n",
    "        # Sort by character at 26th place (digit)\n",
    "        file_num = int(re.split('([0-9]+)',file)[1])\n",
    "        return(file_num)\n",
    "        \n",
    "    def _sample_to_time(self, sampleFreq):\n",
    "        # Convert sample to time\n",
    "        # time per frequency sample\n",
    "        time_per_sample = 1/sampleFreq\n",
    "        # Get time stamp for pressuse u(t) by multiplying time per sample * sample[i]\n",
    "        time_stamp = np.tile(np.arange(self._n_signal_samples), \n",
    "                             self.n_data_samples).reshape([self.n_data_samples,-1]) * time_per_sample[:,None]\n",
    "        # Repeats for all channels and all data samples for convience\n",
    "        # Shape: (num of data samples, num of channels, num of signal samples)\n",
    "        self.time = np.tile(time_stamp,self._n_channels).reshape([self.n_data_samples,-1,self._n_signal_samples])\n",
    "\n",
    "    def _geometry_to_space(self):\n",
    "        # TODO: might be easier to use numpy tile instead\n",
    "        # make a array of ones shape: (num of data samples, num of channels, dimensions)\n",
    "        # dimensions => num of dimension of the array coordinate\n",
    "        geo_dummy = np.ones([self.n_data_samples, *self.arr_geometry.shape], dtype=np.float32)\n",
    "        # Each data sample has the same array geometry then add a dimension for num of signal samples\n",
    "        # Shape: (num of data samples, num of channels, 1, dimensions)\n",
    "        geo_expand = np.expand_dims(geo_dummy * self.arr_geometry, axis=2)\n",
    "        # Each signal samples has the same array geometry\n",
    "        # shape: (num of data samples, num of channels, num of signal samples, dimension)\n",
    "        self.space = np.ones([self.n_data_samples, self._n_channels, self._n_signal_samples,\n",
    "                              geo_expand.shape[-1]], dtype=np.float32) * geo_expand\n",
    "        \n",
    "    def _extract_signal_info(self):\n",
    "        # Source signal information files\n",
    "        files_dat = [i for i in os.listdir(self._path_dir) if os.path.isfile(os.path.join(self._path_dir,i)) and \\\n",
    "                 '.dat' in i]\n",
    "        self._files_dat = sorted(files_dat, key = self._key)   \n",
    "        \n",
    "        # Extract signal information\n",
    "        dats = []\n",
    "        for file in self._files_dat:\n",
    "            with open(self._path_dir+file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for i,l in enumerate(lines):\n",
    "                    dat = [float(i) for i in l.split()]\n",
    "                    dats.append(dat)\n",
    "        # To numpy \n",
    "        dats = np.array(dats, dtype=np.float32)\n",
    "        \n",
    "        # number of data samples / size\n",
    "        self.n_data_samples = len(dats)\n",
    "        \n",
    "        # Convert sample to time\n",
    "        self._sample_to_time(dats[:,0])\n",
    "\n",
    "        # Get theta\n",
    "        angles = dats[:,2]\n",
    "        # Repeat for all channels and all signal samples so each data samples shouldve the same theta for convience\n",
    "        # Shape: (num of data samples, num of channels, num of signal samples)\n",
    "        self.theta = np.repeat(angles, self._n_channels * \n",
    "                               self._n_signal_samples).reshape((self.n_data_samples, self._n_channels, -1))\n",
    "\n",
    "    def _extract_raw_signal(self):\n",
    "        # raw signals files\n",
    "        files_raw = [i for i in os.listdir(self._path_dir) if os.path.isfile(os.path.join(self._path_dir,i)) and \\\n",
    "                           'raw.bin' in i]\n",
    "        self._files_raw = sorted(files_raw, key = self._key)   \n",
    "        \n",
    "        # Extract signals\n",
    "        signals = []\n",
    "        for file in self._files_raw:\n",
    "            with open(self._path_dir+file, 'rb') as f:\n",
    "                signal = f.read()\n",
    "                signal = np.frombuffer(signal, dtype = np.float32)\n",
    "                signals.append(signal)\n",
    "        signals_np = np.array(signals, dtype=np.float32)\n",
    "        signals_np = signals_np.reshape(-1, self._n_signal_samples, self._n_channels)\n",
    "        # Raw pressure u\n",
    "        # Shape: (num of data samples, num of channels, num of signal samples)\n",
    "        self.pres = np.matrix_transpose(signals_np)\n",
    "\n",
    "    def _pack_data(self):\n",
    "        # dimension\n",
    "        space_dim = self.space.shape[-1]\n",
    "        # pack each space, time, pressure and theta into a set\n",
    "        self.space_time_pres_theta = np.empty([*self.time.shape, space_dim + 3], dtype=np.float32)\n",
    "        self.space_time_pres_theta[:,:,:,:-3] = self.space\n",
    "        self.space_time_pres_theta[:,:,:,-3] = self.time\n",
    "        self.space_time_pres_theta[:,:,:,-2] = self.pres\n",
    "        self.space_time_pres_theta[:,:,:,-1] = self.theta\n",
    "        \n",
    "    def set_bound(self, lower = 0.0, upper = 360.0):\n",
    "        # get data in a bounded angles\n",
    "        # since the theta is the same for all channels and signal in a data sample\n",
    "        mask = np.logical_and(self.theta >= lower, self.theta <= upper)[:,0,0]\n",
    "        self.sub_space_time_pres_theta = self.space_time_pres_theta[mask]\n",
    "\n",
    "    def get_data(self, channels=None):\n",
    "        # If no channels are specify\n",
    "        # Default to channels from 0 to 23\n",
    "        if not channels:\n",
    "            channels = np.arange(0,24, dtype=int)\n",
    "        return self.sub_space_time_pres_theta[:,channels]\n",
    "        \n",
    "    def plot(self, channels = None):\n",
    "        if not channels:\n",
    "            channels = list(range(0,self._n_channels))\n",
    "        # Time delay vs angle at different channel\n",
    "        fig = plt.figure(figsize = (20,20))\n",
    "        ax = plt.axes()\n",
    "        colors = cm.rainbow(np.linspace(0, 1, self._n_channels))\n",
    "        for i in range(len(channels)):\n",
    "            ax.scatter(self.angles, self.time_delays[:,channels[i]], label=\"ch{}\".format(i), s=0.5,color=colors[channels[i]])\n",
    "        plt.title(\"Time Delay vs. DOA for Each Channel\")\n",
    "        ax.grid()\n",
    "        ax.set_xlabel('DOA (degree)', fontweight ='bold') \n",
    "        ax.set_ylabel('Time Delay (ms)', fontweight ='bold') \n",
    "        ax.legend(markerscale = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c03eab-0d42-44e6-9d2b-ad536c53956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, space_time_pres_theta):\n",
    "        # dataloader\n",
    "        self.dataloader = None\n",
    "        self.train_dataloader = None\n",
    "        self.val_dataloader = None\n",
    "        self.test_dataloader = None\n",
    "        \n",
    "        # Input for model: space and time\n",
    "        self.space_time = None\n",
    "        # Output for model: pressure and theta\n",
    "        self.pres = None\n",
    "        self.theta = None\n",
    "\n",
    "        # the shape of data after permute: (num of data samples, num of signal samples, num of channels, (space, time, pressure, theta))\n",
    "        # After reshape, each data point is a (space, time, pressure, theta)\n",
    "        self._data = np.permute_dims(space_time_pres_theta, axes = (0,2,1,3))\n",
    "        self._data = self._data.reshape([-1, self._data.shape[-2], self._data.shape[-1]])\n",
    "        # numpy array to tensor and shuffle along the dimension 0\n",
    "        self._data = tf.random.shuffle(self._data)\n",
    "\n",
    "        # Unpacking the given data into separate arrays space, time, pressure, and theta\n",
    "        self._unpack_data()\n",
    "\n",
    "        # pack data into tensorflow dataloader\n",
    "        self._pack_dataloader()\n",
    "\n",
    "    def _unpack_data(self):\n",
    "        # Unpacking the given data into separate arrays space, time, pressure, and theta\n",
    "        # For space, space has different dimension\n",
    "        # Since the time, pressure, and theta occupied the last 3 elements of each data point\n",
    "        #self.space = self._data[:,:-3]\n",
    "        #self.time = self._data[:,-3]\n",
    "        self.space_time = self._data[:,:,:-2]\n",
    "        self.pres = tf.expand_dims(self._data[:,:,-2], axis=-1)\n",
    "        # since all channels has the same theta\n",
    "        self.theta = tf.expand_dims(self._data[:,:,-1], axis=-1)\n",
    "        \n",
    "    def _pack_dataloader(self):\n",
    "        # pack data into tensorflow dataloader\n",
    "        #self.dataloader = tf.data.Dataset.from_tensor_slices(((self.space, self.time), (self.pres, self.theta)))\n",
    "        self.dataloader = tf.data.Dataset.from_tensor_slices((self.space_time, self.pres, self.theta))\n",
    "        \n",
    "    def _shuffle_dataloader(self, buffer_size):\n",
    "        # shuffle dataset\n",
    "        if buffer_size == -1:\n",
    "            self.dataloader = self.dataloader.shuffle(self.dataloader.cardinality())\n",
    "        else:\n",
    "            self.dataloader = self.dataloader.shuffle(buffer_size = buffer_size)\n",
    "        \n",
    "    def split(self, ratio=[0.7,0.15,0.15], shuffle=True, shuffle_buffer_size = 5):\n",
    "        # return splits\n",
    "        dataset_size = len(self._data)\n",
    "        if shuffle:\n",
    "            self._shuffle_dataloader(shuffle_buffer_size)\n",
    "        if len(ratio) == 3:\n",
    "            train_size = int(ratio[0]*dataset_size)\n",
    "            val_size = int(ratio[1]*dataset_size)\n",
    "            test_size = int(ratio[2]*dataset_size)\n",
    "            self.train_dataloader = self.dataloader.take(train_size)\n",
    "            self.test_dataloader = self.dataloader.skip(train_size)\n",
    "            self.val_dataloader = self.dataloader.skip(test_size)\n",
    "            self.test_dataloader = self.dataloader.take(test_size)\n",
    "            return self.train_dataloader, self.val_dataloader, self.test_dataloader\n",
    "        else:\n",
    "            train_size = int(ratio[0]*dataset_size)\n",
    "            test_size = int(ratio[1]*dataset_size)\n",
    "            self.train_dataloader = self.dataloader.take(train_size)\n",
    "            self.test_dataloader = self.dataloader.skip(train_size)\n",
    "            return self.train_dataloader, self.test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23695a54-32ac-4140-a91a-326ff99e6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, AA_geometry):\n",
    "        self._AA_geometry_cart = AA_geometry\n",
    "        self._AA_geometry_polar = np.empty(AA_geometry[:,:2].shape)\n",
    "        self._AA_geometry_sphe = np.empty(AA_geometry.shape)\n",
    "        self._cart2pol()\n",
    "        self._cart2sphe()\n",
    "    def cartesian2D(self, fig_size = (12,12)):\n",
    "        fig = plt.figure(figsize = fig_size)\n",
    "        ax = plt.axes()\n",
    "        for i, channel in enumerate(self._AA_geometry_cart):\n",
    "            ax.scatter(channel[0],channel[1], label = \"ch{}\".format(i))\n",
    "            ax.text(channel[0], channel[1], '  %s'%(str(i)))\n",
    "        plt.title(\"Array Cartesian Top View\", pad = 25)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlabel('X-axis', fontweight ='bold') \n",
    "        ax.set_ylabel('Y-axis', fontweight ='bold') \n",
    "        ax.margins(0.2)\n",
    "        ax.legend()\n",
    "        #plt.tight_layout()\n",
    "    def cartesian3D(self, fig_size = (12,12)):\n",
    "        fig = plt.figure(figsize = fig_size)\n",
    "        ax = plt.axes(projection = \"3d\")\n",
    "        for i, channel in enumerate(self._AA_geometry_cart):\n",
    "            ax.scatter(channel[0],channel[1],channel[2], label = \"ch{}\".format(i))\n",
    "            ax.text(channel[0], channel[1], channel[2], '  %s'%(str(i)), position=(1,1))\n",
    "        plt.title(\"Array Cartesian 3D View\", pad = 25)\n",
    "        ax.set_xlabel('X-axis', fontweight ='bold') \n",
    "        ax.set_ylabel('Y-axis', fontweight ='bold') \n",
    "        ax.set_zlabel('Z-axis', fontweight ='bold')\n",
    "        ax.legend()\n",
    "    def polar(self, angle_1 = None, angle_2 = None, channels = [], fig_size = (15,14), save_dir = None):\n",
    "        fig = plt.figure(figsize = fig_size)\n",
    "        ax = plt.axes(projection = \"polar\")\n",
    "        colors = cm.rainbow(np.linspace(0, 1, 24))\n",
    "        for i, channel in enumerate(self._AA_geometry_polar):\n",
    "            if i in channels:\n",
    "                ax.scatter(channel[1],channel[0], s=300, marker=\"X\", label = \"ch{}\".format(i), color=colors[i])\n",
    "                ax.text(channel[1], channel[0], '  %s'%(str(i)) )\n",
    "                continue\n",
    "            ax.scatter(channel[1],channel[0], label = \"ch{}\".format(i), color=colors[i])\n",
    "            ax.text(channel[1], channel[0], '  %s'%(str(i)) )\n",
    "                \n",
    "        if angle_1:\n",
    "            angle = angle_1 * np.pi / 180\n",
    "            ax.vlines(angle,0,0.12, colors = 'r')\n",
    "        if angle_2:\n",
    "            angle = angle_2 * np.pi / 180\n",
    "            ax.vlines(angle,0,0.12, colors = 'g')\n",
    "        plt.title(\"Array Cartesian 3D View\", pad = 25)\n",
    "        ax.margins(0.2)\n",
    "        if save_dir:\n",
    "            fig.savefig(save_dir+'AA_polar.png')\n",
    "            \n",
    "    def plot_dataset(self, dataset):\n",
    "        input_dataset = []\n",
    "        label_dataset = []\n",
    "        for x,_,y in dataset:\n",
    "            input_dataset.append(x)\n",
    "            label_dataset.append(y)\n",
    "        input_dataset = np.array(input_dataset)\n",
    "        label_dataset = np.array(label_dataset)\n",
    "        \n",
    "        fig = plt.figure(figsize = (20,20))\n",
    "        ax = plt.axes()\n",
    "        for i in range(input_dataset.shape[1]):\n",
    "            ax.scatter(label_dataset, input_dataset[:,[i]], label=\"ch{}\".format(i))\n",
    "        plt.title(\"Time Delay vs. DOA for Each Channel\")\n",
    "        ax.set_xlabel('DOA (degree)', fontweight ='bold') \n",
    "        ax.set_ylabel('Time Delay (ms)', fontweight ='bold') \n",
    "        ax.legend()\n",
    "    def _cart2pol(self):\n",
    "        for i, channel in enumerate(AA_Geometry):\n",
    "            x = channel[0]\n",
    "            y = channel[1]\n",
    "            r = np.sqrt(x**2 + y**2)\n",
    "            if x == 0:\n",
    "                theta = np.pi/2 if y > 0 else -np.pi/2\n",
    "            else:\n",
    "                theta = np.arctan(y/x)# * 180 / np.pi\n",
    "                theta = theta if x > 0 else theta + np.pi\n",
    "            self._AA_geometry_polar[i][0] = r\n",
    "            self._AA_geometry_polar[i][1] = theta\n",
    "    def _cart2sphe(self):\n",
    "        pass\n",
    "        #for i in range(self._AA_geometry_cart.shape[1]):\n",
    "        #    x = self._AA_geometry_cart[0][i] + 0.0001\n",
    "        #    y = self._AA_geometry_cart[1][i] + 0.0001\n",
    "        #    z = self._AA_geometry_cart[2][i] + 0.0001\n",
    "        #    \n",
    "        #    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        #    theta = np.arctan(y/x)\n",
    "        #    phi = np.arccos(z/r)\n",
    "        #    self._AA_geometry_sphe[:,i] = np.array([r,theta,phi])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0e1952-2728-4aba-bcd6-14c080aa8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel:\n",
    "    def __init__(self, model, channel_id, dataset):\n",
    "        self._model = model\n",
    "        self._channel_id = channel_id\n",
    "        self._dataset = dataset\n",
    "    def plot_training(self, losses):\n",
    "        metrics = list(losses.history.keys())\n",
    "        fig, axs = plt .subplots(ncols = 3, nrows=1, figsize=(12,3), layout=\"constrained\")\n",
    "        for i in range(3):\n",
    "            axs[i].plot(losses.history[metrics[i]], label=\"train_{}\".format(metrics[i]))\n",
    "            axs[i].plot(losses.history[metrics[i+3]], label=metrics[i+3])\n",
    "            axs[i].set_yscale('log')\n",
    "            axs[i].legend()\n",
    "        fig.supxlabel(\"epoch\")\n",
    "        fig.suptitle(\"Channels: {}\".format(\" \".join(str(ch) for ch in self._channel_id)))\n",
    "\n",
    "    def plot_evaluation(self, lower=0.0, upper=360.0, verbose = False, save_dir = None):\n",
    "        fig, axs = plt.subplots(ncols = 1, nrows = len(self._channel_id) + 2, figsize = (20,len(self._channel_id)*3), layout=\"constrained\")\n",
    "        for x,c,y in self._dataset.batch(len(self._dataset)):\n",
    "            # Targeting a specific range\n",
    "            fillter = np.logical_and(y >= lower, y <= upper).flatten()\n",
    "            x, y = x[fillter], y[fillter]\n",
    "            y_pred, c_pred = self._model.predict(x, verbose=False)\n",
    "            if verbose:\n",
    "                print(\"Inputs\")\n",
    "                print(x)\n",
    "                print(\"Y Truth\", \"Y Predict\")\n",
    "                print(np.stack((y, y_pred),axis=1).squeeze(-1))\n",
    "            for i in range(x.shape[1]):\n",
    "                axs[i].scatter(y, x[:,i], color='r', s=5)\n",
    "                axs[i].scatter(y_pred, x[:,i], color='b', s=5)\n",
    "                axs[i].set_title(\"Channel {}\".format(self._channel_id[i]))\n",
    "                axs[i].grid()\n",
    "\n",
    "            # Absolute different\n",
    "            axs[-2].scatter(y, y-y_pred, color='g', s=5)\n",
    "            axs[-2].set_title(\"Truth vs Predict absolute different\")\n",
    "            axs[-2].grid()\n",
    "            \n",
    "            # Relative different\n",
    "            y_diff = lambda y, y_hat : ((y - y_hat) + 180) % 360 -180\n",
    "            axs[-1].scatter(y, y_diff(y, y_pred), color='g', s=5)\n",
    "            axs[-1].set_title(\"Truth vs Predict relative different\")\n",
    "            axs[-1].grid()\n",
    "        if save_dir:\n",
    "            ch2str = \"\"\n",
    "            for ch in channel_id:\n",
    "                ch2str += \"_{}\".format(ch)\n",
    "            fig.savefig(save_dir + \"evaluation_ch{}.png\".format(ch2str))\n",
    "                            \n",
    "    def evaluate(self, verbose=False):\n",
    "        eva = self._model.evaluate(self._dataset.batch(100), verbose=False)\n",
    "        if verbose:\n",
    "            print(eva)\n",
    "        return eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1326f9f0-9690-44dc-bc91-8524a8e5f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomAA(num_channels, list_length):\n",
    "    list_channels = np.empty([list_length, num_channels], dtype=int)\n",
    "    for i in range(list_length):\n",
    "        list_channels[i] = random.sample(range(0,24), num_channels)\n",
    "    return list_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242ed421-3e83-4ede-80b1-1a7c9d49a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluates_table(model, list_channels, evaluates):\n",
    "    df = pd.DataFrame(np.zeros((len(list_channels), 5), dtype=object), columns=[\"Activation\", \"Channels\", \"Loss\", \"Mae\", \"Mse\"])\n",
    "    for i in range(len(list_channels)):\n",
    "        df.at[i, \"Activation\"] = model\n",
    "        df.at[i, \"Channels\"] = list_channels[i]\n",
    "        df.at[i, \"Loss\"] = evaluates[i][0]\n",
    "        df.at[i, \"Mae\"] = evaluates[i][2]\n",
    "        df.at[i, \"Mse\"] = evaluates[i][1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507256e8-aa86-43f4-b683-f8657b507a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_table(df, col_name, threshold=1):\n",
    "    # Initialize matplot\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax = plt.axes()\n",
    "    # convert pandas dataframe to numpy\n",
    "    target_values = df[col_name].to_numpy()\n",
    "    # number of channels or length\n",
    "    try:\n",
    "        # case if the dataframe entries are in string\n",
    "        num_channels = np.array([len(re.findall(r'\\d+',item['Channels'])) for i,item in df.iterrows()])\n",
    "    except:\n",
    "        # case if the dataframe entries are object\n",
    "        num_channels = np.array([len(item['Channels']) for i,item in df.iterrows()])\n",
    "    mean = target_values.mean()\n",
    "    std = target_values.std()\n",
    "    # z scores\n",
    "    zs = (target_values - mean) / std\n",
    "    # Find the target values within the threshold if not mask with NaN\n",
    "    plot_points = np.where(zs<threshold,target_values,np.nan)\n",
    "    # Plot points vs number of channels\n",
    "    ax.scatter(plot_points, num_channels, s = 5) \n",
    "    ax.grid(linestyle='--')\n",
    "    ax.set_yticks(list(range(3,25,3)))\n",
    "    ax.set_xlabel('Number of Channels', fontweight ='bold') \n",
    "    ax.set_ylabel(col_name, fontweight ='bold') \n",
    "    plt.title(\"Models Performance by \" + col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1342a-e9d3-430d-a428-a6357c0e50bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e559a1d-8446-4ca7-84d8-efc7db330869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 15:18:04.678394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745853484.688745  985715 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745853484.691911  985715 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-28 15:18:04.703462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf038e5-c6bb-41b0-b714-9923a875600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, n_channels, he_initializer = True, floormod=False):\n",
    "        super().__init__()\n",
    "        # Fixed metrics\n",
    "        self.mse_metric = CustomMSE(name='mse')\n",
    "        self.mae_metric = CustomMAE(name='mae')\n",
    "\n",
    "        # Use floormod\n",
    "        self.floormod = floormod\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "       \n",
    "        self.initializer = tf.keras.initializers.HeNormal(1561)\n",
    "        if not he_initializer:\n",
    "            self.initializer = tf.keras.initializers.GlorotUniform(1561)\n",
    "        # input shape of net: (batch size, number of channels, 3 for (x,y,t))\n",
    "        # output shape of net: (batch size, number of channels, 32)\n",
    "        # output shape of pressure_net: (batct size, number of channels,)\n",
    "        # output shape of theta_net: (batct size, number of channels,)\n",
    "        self.net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=[self.n_channels,3]),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=64, activation='tanh', kernel_initializer = self.initializer)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=64, activation='tanh', kernel_initializer = self.initializer)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=32, activation='tanh', kernel_initializer = self.initializer))\n",
    "        ]) \n",
    "        \n",
    "        self.pressure_net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=32, activation='tanh', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=self.n_channels, activation = 'linear')\n",
    "        ])\n",
    "        \n",
    "        self.theta_net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=16, activation='softplus', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=8, activation='softplus', kernel_initializer = self.initializer),\n",
    "            tf.keras.layers.Dense(units=self.n_channels, activation = 'softplus')\n",
    "        ])\n",
    "        \n",
    "        self.lambda_data = tf.keras.Variable(1.0, name='lambda_data', dtype=tf.float32)  \n",
    "        self.lambda_phys = tf.keras.Variable(-10.0, name='lambda_phys', dtype=tf.float32)  \n",
    "        self.lambda_theta = tf.keras.Variable(1.0, name='lambda_theta', dtype=tf.float32)  \n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "    def normalize_inputs(self, space_time):\n",
    "        # Assuming inputs have the shape (batch_size, 3), with (x, y, t)\n",
    "        # Use precomputed mean and std\n",
    "        mean = tf.math.reduce_mean(space_time, axis=(0,1))\n",
    "        std = tf.math.reduce_std(space_time, axis=(0,1))\n",
    "        return (space_time - mean) / std\n",
    "\n",
    "    def compute_loss(self, y, y_pred):\n",
    "        #pres_actual, theta_actual = y_actual[:,0], y_actual[:,1]\n",
    "        #pres_pred, theta_pred, d2u_dx2, d2u_dy2, d2u_dt2 = y_pred[:,0], y_pred[:,1], y_pred[:,2], y_pred[:,3], y_pred[:,4]\n",
    "        pres_actual, theta_actual = tf.split(y, 2, axis=-1)\n",
    "        pres_pred, theta_pred, d2u_dx2, d2u_dy2, d2u_dt2 = tf.split(y_pred, 5, axis=-1)\n",
    "        \n",
    "        # data loss\n",
    "        #data_loss = tf.exp(self.lambda_data)*self.loss.data_loss(pres_actual, pres_pred)\n",
    "        data_loss = 1.0*self.loss.data_loss(pres_actual, pres_pred)\n",
    "        \n",
    "        # physic loss\n",
    "        #phys_loss= tf.exp(self.lambda_phys)*self.loss.phys_loss(d2u_dx2, d2u_dy2, d2u_dt2)\n",
    "        phys_loss= 0.001*self.loss.phys_loss(d2u_dx2, d2u_dy2, d2u_dt2)\n",
    "        \n",
    "        # theta loss\n",
    "        #theta_loss = tf.exp(self.lambda_theta)*self.loss.theta_loss(theta_actual, theta_pred)\n",
    "        theta_loss = 10.0*self.loss.theta_loss(theta_actual, theta_pred)\n",
    "        \n",
    "        #tf.print(data_loss, phys_loss, theta_loss)\n",
    "        return data_loss + phys_loss + theta_loss\n",
    "\n",
    "    def compute_second_order(self, space_time):\n",
    "        # Tracking the second order derivatives with respect to space and time\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch(space_time)\n",
    "            with tf.GradientTape(persistent=True) as tape1:\n",
    "                tape1.watch(space_time)\n",
    "                pres_pred,_ = self(space_time)\n",
    "                \n",
    "            # First order derivative: du/dx, du/dy, du/dt\n",
    "            first_order = tape1.gradient(pres_pred, space_time)\n",
    "\n",
    "        # Second order derivative: d^2u/dx^2, d^2u/dy^2, d^2u/dt^2\n",
    "        second_order = tape2.gradient(first_order, space_time)\n",
    "        \n",
    "        # free memory\n",
    "        del tape1, tape2\n",
    "        return second_order\n",
    "        \n",
    "    def train_step(self, dataset):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        # Shape space_time: (batch_size, n_channels, 3)\n",
    "        # shape pressure: (batch_size, n_channels, 1)\n",
    "        # Shape theta: (batch_size, 1, 1)\n",
    "        space_time, pres, theta = dataset\n",
    "        with tf.GradientTape() as tape:\n",
    "            # TODO\n",
    "            pres_pred, theta_pred = self(space_time, training=True)  # Forward pass\n",
    "            pres_pred = tf.expand_dims(pres_pred, axis=-1)\n",
    "            theta_pred = tf.expand_dims(theta_pred, axis=-1)\n",
    "\n",
    "            # Tracking the second order derivatives with respect to space and time\n",
    "            #d2u_dx2, d2u_dy2, d2u_dt2 = self.compute_second_order(space_time)\n",
    "            second_order = self.compute_second_order(space_time)\n",
    "\n",
    "            # Compute the loss value\n",
    "            # packing for y and y_pred \n",
    "            y = tf.concat([pres,theta], axis=-1)\n",
    "            y_pred = tf.concat([pres_pred, theta_pred, second_order], axis=-1)\n",
    "            loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        #self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        # Update metrics\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(theta, theta_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        \n",
    "    def test_step(self, dataset):\n",
    "        space_time, pres, theta = dataset\n",
    "        pres_pred, theta_pred = self(space_time, training=False)  # Forward pass\n",
    "        \n",
    "        pres_pred = tf.expand_dims(pres_pred, axis=-1)\n",
    "        theta_pred = tf.expand_dims(theta_pred, axis=-1)\n",
    "\n",
    "\n",
    "        # Tracking the second order derivatives with respect to space and time\n",
    "        #d2u_dx2, d2u_dy2, d2u_dt2 = self.compute_second_order(space_time)\n",
    "        second_order = self.compute_second_order(space_time)\n",
    "\n",
    "        # Compute the loss value\n",
    "        # packing for y and y_pred \n",
    "        y = tf.concat([pres,theta], axis=-1)\n",
    "        y_pred = tf.concat([pres_pred, theta_pred, second_order], axis=-1)\n",
    "        #y_pred = tf.concat([pres_pred, theta_pred, d2u_dx2, d2u_dy2, d2u_dt2], axis=1)\n",
    "        #self.loss.set_lambdas(self.lambda_data, self.lambda_phys, self.lambda_theta)\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        \n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(theta, theta_pred)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = self.normalize_inputs(inputs)\n",
    "        output = self.net(inputs)\n",
    "        pressure = self.pressure_net(output)\n",
    "        theta = self.theta_net(output)\n",
    "        if self.floormod:\n",
    "            # In case the prediction is outside of range of 0 to 360\n",
    "            theta = tf.math.floormod(theta,360.0)\n",
    "        return pressure, theta\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inputs = self.normalize_inputs(inputs)\n",
    "        output = self.net(inputs)\n",
    "        pressure = self.pressure_net(output)\n",
    "        theta = self.theta_net(output)\n",
    "        return pressure, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4cf220-a56d-47dc-ad45-f5ab0a4910a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPINNLoss\u001b[39;00m(\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mLoss):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# PINN Loss introducing physic to the model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# This loss has 3 parts\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Data loss which is the loss of the pressure field u(x,y,t) , where x,y are space and t is time\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Physical loss which is the wave equation d^2u/dt^2 = C^2 * (d^2u/dx^2 + d^2u/dy^2)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# This will help the model understanding the physical constraint and stablizing the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Theta loss is the loss of the theta or angle\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class PINNLoss(tf.keras.losses.Loss):\n",
    "    # PINN Loss introducing physic to the model\n",
    "    # This loss has 3 parts\n",
    "    # Data loss which is the loss of the pressure field u(x,y,t) , where x,y are space and t is time\n",
    "    # Physical loss which is the wave equation d^2u/dt^2 = C^2 * (d^2u/dx^2 + d^2u/dy^2)\n",
    "    # This will help the model understanding the physical constraint and stablizing the model\n",
    "    # Theta loss is the loss of the theta or angle\n",
    "    def __init__(self, name=\"loss\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        # constant sound speed\n",
    "        # TODO: noisy sound speed\n",
    "        self.C = 343.0\n",
    "        \n",
    "    def theta_loss(self, y_actual, y_pred):\n",
    "        # cosine loss for loss in the horizontal direction\n",
    "        # sine loss for loss in the vertical direction\n",
    "        \n",
    "        # convert degree to radian\n",
    "        actual_rad = y_actual*np.pi/180\n",
    "        pred_rad = y_pred*np.pi/180\n",
    "    \n",
    "        # the cosine and sine loss\n",
    "        cos_loss = tf.math.reduce_mean(tf.math.square(1 - tf.math.cos(actual_rad - pred_rad)))\n",
    "        sin_loss = tf.math.reduce_mean(tf.math.square(tf.math.sin(actual_rad - pred_rad)))\n",
    "        \n",
    "        # loss \n",
    "        loss = (cos_loss + sin_loss)\n",
    "        return loss\n",
    "\n",
    "    def data_loss(self, pres_actual, pres_pred):\n",
    "        # Wave pressure at some (x,t)\n",
    "        loss = tf.math.reduce_mean(tf.math.square(pres_actual - pres_pred))\n",
    "        return loss\n",
    "        \n",
    "    def phys_loss(self, d2u_dx2, d2u_dy2, d2u_dt2):\n",
    "        # pres_time: the second order derivative of the wave pressure respect to time\n",
    "        # pres_space: the second order derivative of the wave pressure respect to space\n",
    "        pres_time = d2u_dt2\n",
    "        pres_space = (self.C**2) * (d2u_dx2 + d2u_dy2)\n",
    "        loss = tf.math.reduce_mean(tf.math.square(pres_time - pres_space))\n",
    "        return loss\n",
    "        \n",
    "    def speed_loss(self, c_actual, c_pred):\n",
    "        # sound speed through medium\n",
    "        loss = tf.math.reduce_mean(tf.math.square(c_actual - c_pred))\n",
    "        return loss\n",
    "        \n",
    "    def call(self, y_actual, y_pred):\n",
    "        raise NotImplementedError(\"Loss is used only as helper, model handles total loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a9ad64-d63b-483f-baec-74cc91efefe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCustomMSE\u001b[39;00m(\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMetric):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_mse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(CustomMSE, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomMSE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='custom_mse', **kwargs):\n",
    "        super(CustomMSE, self).__init__(name=name, **kwargs)\n",
    "        # Initialize variables to track squared error and count\n",
    "        self.total_squared_error = self.add_weight(name='total_squared_error', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Compute squared error with cyclic distance correction\n",
    "        squared_error = tf.square(((y_true - y_pred) + 180) % 360 - 180)\n",
    "        \n",
    "        # Apply sample weight if available\n",
    "        if sample_weight is not None:\n",
    "            squared_error = tf.multiply(squared_error, sample_weight)\n",
    "\n",
    "        # Update the total error and count\n",
    "        self.total_squared_error.assign_add(tf.reduce_sum(squared_error))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        # Return the mean squared error\n",
    "        return self.total_squared_error / self.count\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the internal variables at the start of each epoch\n",
    "        self.total_squared_error.assign(0.0)\n",
    "        self.count.assign(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c85e353-597e-497d-8550-cf61d860b2b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCustomMAE\u001b[39;00m(\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMetric):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_mse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(CustomMAE, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomMAE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='custom_mse', **kwargs):\n",
    "        super(CustomMAE, self).__init__(name=name, **kwargs)\n",
    "        # Initialize variables to track squared error and count\n",
    "        self.total_squared_error = self.add_weight(name='total_squared_error', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Compute squared error with cyclic distance correction\n",
    "        squared_error = tf.abs(((y_true - y_pred) + 180) % 360 - 180)\n",
    "        \n",
    "        # Apply sample weight if available\n",
    "        if sample_weight is not None:\n",
    "            squared_error = tf.multiply(squared_error, sample_weight)\n",
    "\n",
    "        # Update the total error and count\n",
    "        self.total_squared_error.assign_add(tf.reduce_sum(squared_error))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        # Return the mean squared error\n",
    "        return self.total_squared_error / self.count\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the internal variables at the start of each epoch\n",
    "        self.total_squared_error.assign(0.0)\n",
    "        self.count.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba9e580-03e7-4819-bdf9-1c05e6fcfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_evaluation(list_channels, AA_geometry, \\\n",
    "                        inputs, speeds, labels, norm, clambda = [1.0,1.0,1.0],\n",
    "                        he_initializer=True, floormod=True, \n",
    "                        epochs = 50, plot = False, save_fig = False,verbose=False):\n",
    "    # trained models\n",
    "    models = []\n",
    "    # models losses history\n",
    "    losses = []\n",
    "    # evluation scores\n",
    "    evaluates = []\n",
    "    # reference channel at channel 0 for time delays\n",
    "    ref_geometry = tf.constant(AA_geometry[0][:2], dtype=float)\n",
    "\n",
    "    # train models for each selected channels in the list of channels\n",
    "    for channels in list_channels:\n",
    "        # Get the geometry of the channels only in x and y planes\n",
    "        array_geometry = tf.constant(AA_geometry[channels][:,:2], dtype=float)\n",
    "        # pack selected channels data into tensorflow dataset\n",
    "        dataset = DataSetPacker(inputs, speeds, labels, channels)\n",
    "        \n",
    "        # split dataset into train, validation, and test dataset\n",
    "        train_dataset, val_dataset, test_dataset = dataset.split(shuffle=False)\n",
    "        # Initialize the model\n",
    "        model = MiniPINN(np.shape(channels), array_geometry, he_initializer, floormod)\n",
    "        # Compile model\n",
    "        model.compile(optimizer='adam', loss=MiniPINNLoss(array_geometry, ref_geometry, norm, clambda))\n",
    "        l = model.fit(train_dataset.batch(32), epochs=epochs, validation_data = val_dataset.batch(32), verbose=verbose)\n",
    "        # Train model\n",
    "        # Get model score\n",
    "        eva = EvaluateModel(model, channels, test_dataset)\n",
    "        eva.evaluate(verbose=True)\n",
    "        #eva = EvaluateModel.evaluate(model, test_dataset, False)\n",
    "        if plot:\n",
    "            if save_fig:\n",
    "                eva.plot_training(l, save_dir = 'plot/history/')\n",
    "                eva.plot_evaluation(save_dir = 'plot/evaluation/')\n",
    "            else:\n",
    "                eva.plot_training(l)\n",
    "                eva.plot_evaluation()\n",
    "        models.append(model)\n",
    "        losses.append(l)\n",
    "        evaluates.append(eva)\n",
    "    return models, evaluates, l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db9172-574d-4391-8f46-4f9266034d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
